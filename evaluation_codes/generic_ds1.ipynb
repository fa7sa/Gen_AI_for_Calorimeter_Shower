{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4173a477-5742-42a0-8faf-6a836fa6517e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import HighLevelFeatures as HLF\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cc4fa8-d4c5-4270-8c9a-2a3ebea0bf19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def file_read(file_name):\n",
    "    with h5py.File(file_name, \"r\") as h5f:\n",
    "        e = h5f['incident_energies'][::].astype(np.float32)  \n",
    "        shower = h5f['showers'][::].astype(np.float32)\n",
    "        \n",
    "    return e, shower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e60ad32-6ce9-42b6-9569-c38cf1352548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_name_part(file_name):\n",
    "    # Use regular expression to extract the desired part of the filename\n",
    "    match = re.search(r'_([^_]+)\\.h5(?:df5)?$', file_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        match = re.search(r'_([^_]+)\\.hdf5$', file_name)\n",
    "        return match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc4e1e-6289-4f2b-ade5-6fde684290fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We have separate directory for each dataset. In the directory we store our generated samples from different models and Geant4. The name pattern of the file is like this 'dataset_n_particleName_x.h5' where n denotes the dataset number, particleName can be photons, pions and electron. x denotes the model Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc0a3ee-1aee-4945-b3b7-55e08ba8a480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change this path according to your need\n",
    "path_to_DS1_photon='/scratch/fa7sa/IJCAI_experiment/homepage/code/Dataset_1_samples_photon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38845126-f995-413b-8004-d7d64743469a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def iterate_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".h5\") or filename.endswith(\".hdf5\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            e,shower=file_read(file_path)\n",
    "            Es.append(e)\n",
    "            Showers.append(shower)\n",
    "            name_part = extract_name_part(filename)\n",
    "            \n",
    "            if name_part:\n",
    "                print(\"Extracted part from filename:\", name_part)\n",
    "                model_names.append(name_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538b296e-48ce-4616-afcb-c3879fea6ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted part from filename: Geant4\n",
      "Extracted part from filename: CaloDiffusion\n",
      "Extracted part from filename: CaloINN\n",
      "Extracted part from filename: CaloScore\n"
     ]
    }
   ],
   "source": [
    "Es=[]\n",
    "Showers=[]\n",
    "model_names=[]\n",
    "\n",
    "iterate_files(path_to_DS1_photon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8967e3a8-6a33-4061-bc6d-b8e7bccf5430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geant4', 'CaloDiffusion', 'CaloINN', 'CaloScore']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47539218-86a7-44e6-b274-56b4f7c67393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _separation_power(hist1, hist2, bins):\n",
    "    \"\"\" computes the separation power aka triangular discrimination (cf eq. 15 of 2009.03796)\n",
    "        Note: the definition requires Sum (hist_i) = 1, so if hist1 and hist2 come from\n",
    "        plt.hist(..., density=True), we need to multiply hist_i by the bin widhts\n",
    "    \"\"\"\n",
    "    hist1, hist2 = hist1*np.diff(bins), hist2*np.diff(bins)\n",
    "    ret = (hist1 - hist2)**2\n",
    "    ret /= hist1 + hist2 + 1e-16\n",
    "    return 0.5 * ret.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd89d15d-49da-42cd-a872-714f07d1d5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change this file path according to your path\n",
    "binning_file=\"/scratch/fa7sa/IJCAI_experiment/homepage/code/binning_dataset_1_photons.xml\"\n",
    "particle='photon'\n",
    "HLFs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb0f41d-39b4-4920-8f1a-72566524bc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(model_names)):\n",
    "    hlf=HLF.HighLevelFeatures(particle,binning_file)\n",
    "    hlf.Einc=Es[i]\n",
    "    hlf.CalculateFeatures(Showers[i])\n",
    "    HLFs.append(hlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634befbe-abc0-4541-aca9-0d49bbe4e6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLFs[0].GetElayers().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ffac6f-d5d6-4708-b09e-771991cdb1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors=['black','blue','green','salmon','orange','yellow']\n",
    "linestyles=['dashed','solid','dotted','dashdot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61124cbe-7a26-4125-9256-e6a68aabd1d0",
   "metadata": {},
   "source": [
    "# plot_E_layers is only called for dataset 1. It shows Layer wise energy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb382656-f2d6-47da-bf49-6c07bd475bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_scale='log'\n",
    "min_energy=10\n",
    "\n",
    "def plot_E_layers(hlf_classes, x_scale,model_names,min_energy):\n",
    "    for key in hlf_classes[0].GetElayers().keys():\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        \n",
    "        if x_scale == 'log':\n",
    "            bins = np.logspace(np.log10(min_energy),\n",
    "                               np.log10(hlf_classes[0].GetElayers()[key].max()),\n",
    "                               40)\n",
    "        else:\n",
    "            bins = 40\n",
    "            \n",
    "        hists=[]\n",
    "            \n",
    "            \n",
    "        for i  in range(len(hlf_classes)):\n",
    "            counts_data, _, _ = plt.hist(hlf_classes[i].GetElayers()[key], label=model_names[i], bins=bins, color=colors[i],\n",
    "                                         histtype='step', linewidth=3., alpha=1., density=True, linestyle=linestyles[i])\n",
    "            hists.append(counts_data)\n",
    "            \n",
    "        plt.title(\"Energy deposited in layer {}\".format(key))\n",
    "        plt.xlabel(r'$E$ [MeV]')\n",
    "        plt.yscale('log')\n",
    "        if x_scale=='log':\n",
    "            plt.xscale('log')\n",
    "        plt.legend(fontsize=20,loc='best')\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        \n",
    "        filename = 'E_layer_{}_dataset_{}.pdf'.format(\n",
    "            key,\n",
    "            '1-photons')\n",
    "        \n",
    "        plt.savefig(filename)\n",
    "        \n",
    "        try:\n",
    "            gi = model_names.index('Geant4')\n",
    "            #print(\"Index of 'Geant4':\", gi)\n",
    "        except ValueError:\n",
    "            print(\"'Geant4' not found in the list.\")\n",
    "            \n",
    "        seps=[]\n",
    "        #print(hists[gi])\n",
    "        for i in range(len(hists)):\n",
    "            #if gi != i:\n",
    "            sep=_separation_power(hists[gi],hists[i],bins)\n",
    "            seps.append(sep)\n",
    "                \n",
    "        with open('histogram_chi2_{}.txt'.format('1-photons'), 'a') as f:\n",
    "            f.write('E layer {}: \\n'.format(key))\n",
    "            for i in range(len(model_names)):\n",
    "                f.write('for {}: {} \\n'.format(model_names[i], seps[i]))\n",
    "            f.write('\\n\\n')\n",
    "            \n",
    "            \n",
    "        plt.close()\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c76b2d-2765-4d44-b09f-92dc948a2c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_E_layers(HLFs,x_scale,model_names,min_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990d329-123a-42e7-80fd-84435336d815",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9dfae-9dde-4bde-bfde-3816873e45b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMPTorch (20201028) Active Learning",
   "language": "python",
   "name": "amptorch-20201028-al"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
